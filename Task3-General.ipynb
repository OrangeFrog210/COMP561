{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training a machine learning classifier to distinguish between bound and unbound sites\n",
    "GB Shape: http://rohsdb.cmb.usc.edu/\n",
    "\"Predicted structural properties for every human genome positions are available here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. Data-Preprocessing: \n",
    "## Mini-objective: Given an input, predict whether the site is bound or unbound\n",
    "Assumption: All the input sequence is of length 20bp (length of a TBP binding site) and it should be bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from random import sample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_overall = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Looking at Position Weight Matrix (PWM) of TBP\n",
    "tf = 'TBP'\n",
    "dnashape_pos = \"phpYwJDXp_pos\"\n",
    "dnashape_neg = \"phpnRRPIR_neg\"\n",
    "zipname_pos = \"phpYwJDX\"\n",
    "zipname_neg = \"phpnRRPIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_name: TBP\n",
      "tf_len: 20\n",
      "TBP\n",
      "80\n",
      "[[0.088608 0.189873 0.202532 0.139241 0.139241 0.189873 0.196203 0.113924\n",
      "  0.082278 0.14557  0.044304 0.037975 0.126582 0.012658 0.316456 0.031646\n",
      "  0.955696 0.056962 0.898734 0.170886]\n",
      " [0.563291 0.43038  0.316456 0.405063 0.35443  0.512658 0.411392 0.322785\n",
      "  0.5      0.329114 0.417722 0.689873 0.170886 0.088608 0.       0.\n",
      "  0.018987 0.006329 0.031646 0.234177]\n",
      " [0.227848 0.259494 0.360759 0.386076 0.424051 0.21519  0.246835 0.417722\n",
      "  0.278481 0.35443  0.443038 0.050633 0.       0.       0.       0.\n",
      "  0.       0.       0.050633 0.525316]\n",
      " [0.120253 0.120253 0.120253 0.06962  0.082278 0.082278 0.14557  0.14557\n",
      "  0.139241 0.170886 0.094937 0.221519 0.702532 0.898734 0.683544 0.968354\n",
      "  0.025316 0.936709 0.018987 0.06962 ]]\n",
      "[1.       1.       1.       1.       1.       0.999999 1.       1.000001\n",
      " 1.       1.       1.000001 1.       1.       1.       1.       1.\n",
      " 0.999999 1.       1.       0.999999]\n"
     ]
    }
   ],
   "source": [
    "with open('factorbookMotifPwm.txt') as f:\n",
    "    for line in f:\n",
    "        if tf in line:\n",
    "            line = line.split(\",\")\n",
    "            for i in range(len(line)):\n",
    "                if i == 0:\n",
    "                    tf_name = line[i].split(\"\\t\")[0]\n",
    "                    tf_len = line[i].split(\"\\t\")[1]\n",
    "                    tf_len = int(tf_len)\n",
    "                    print(\"tf_name:\", tf_name)\n",
    "                    print(\"tf_len:\", tf_len)\n",
    "                    line[i] = line[i].split(\"\\t\")[-1]\n",
    "                else:\n",
    "                    line[i] = line[i].replace(\"\\t\", \"\")\n",
    "            del line[-1]\n",
    "            #tf_name = line[0]\n",
    "            print(tf_name)\n",
    "            #print(line)\n",
    "            print(len(line))\n",
    "            line_int = [float(i) for i in line]\n",
    "            # Convert to a numpy array\n",
    "            pwm_arr = np.array(line_int)\n",
    "            pwm_arr.astype(int)\n",
    "            #print(pwm_arr)\n",
    "            pwm_arr2 = np.reshape(pwm_arr, (4, tf_len))\n",
    "            print(pwm_arr2)\n",
    "            print(np.sum(pwm_arr2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.189873\n",
      "[[0.088608 0.189873 0.202532 0.139241 0.139241 0.189873 0.196203 0.113924\n",
      "  0.082278 0.14557  0.044304 0.037975 0.126582 0.012658 0.316456 0.031646\n",
      "  0.955696 0.056962 0.898734 0.170886]\n",
      " [0.563291 0.43038  0.316456 0.405063 0.35443  0.512658 0.411392 0.322785\n",
      "  0.5      0.329114 0.417722 0.689873 0.170886 0.088608 0.       0.\n",
      "  0.018987 0.006329 0.031646 0.234177]\n",
      " [0.227848 0.259494 0.360759 0.386076 0.424051 0.21519  0.246835 0.417722\n",
      "  0.278481 0.35443  0.443038 0.050633 0.       0.       0.       0.\n",
      "  0.       0.       0.050633 0.525316]\n",
      " [0.120253 0.120253 0.120253 0.06962  0.082278 0.082278 0.14557  0.14557\n",
      "  0.139241 0.170886 0.094937 0.221519 0.702532 0.898734 0.683544 0.968354\n",
      "  0.025316 0.936709 0.018987 0.06962 ]]\n"
     ]
    }
   ],
   "source": [
    "print(pwm_arr2[0,1])\n",
    "print(pwm_arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determination of threshold\n",
    "* Already have: the actual sequences of positive examples\n",
    "* From: these sequences (fasta file containing them)\n",
    "* Calculate the average log probability of all the positive examples\n",
    "* Use this average log probability as the threshold when identifying the unbound sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX']\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "list_chrs = ['chr%s' % s for s in range(1,23)]\n",
    "list_chrs.append(\"chrX\")\n",
    "print(list_chrs)\n",
    "print(len(list_chrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chom:  chr1\n",
      "# of seqs:  29\n",
      "count:  8\n",
      "avg_logprob:  -5.383151466804802\n",
      "max_logprob:  -21.0973227165288\n",
      "=============\n",
      "max_logprob_all:  -21.0973227165288\n",
      "chom:  chr2\n",
      "# of seqs:  26\n",
      "count:  5\n",
      "avg_logprob:  -3.725741712881075\n",
      "max_logprob:  -21.328758721894815\n",
      "=============\n",
      "max_logprob_all:  -21.328758721894815\n",
      "chom:  chr3\n",
      "# of seqs:  20\n",
      "count:  5\n",
      "avg_logprob:  -4.706430258460941\n",
      "max_logprob:  -19.971511456079035\n",
      "=============\n",
      "max_logprob_all:  -21.328758721894815\n",
      "chom:  chr4\n",
      "# of seqs:  14\n",
      "count:  2\n",
      "avg_logprob:  -2.8620554715042905\n",
      "max_logprob:  -21.14473226712874\n",
      "=============\n",
      "max_logprob_all:  -21.328758721894815\n",
      "chom:  chr5\n",
      "# of seqs:  15\n",
      "count:  3\n",
      "avg_logprob:  -3.9182790007898642\n",
      "max_logprob:  -21.195684381362636\n",
      "=============\n",
      "max_logprob_all:  -21.328758721894815\n",
      "chom:  chr6\n",
      "# of seqs:  50\n",
      "count:  8\n",
      "avg_logprob:  -2.9044375994823075\n",
      "max_logprob:  -20.12752208581302\n",
      "=============\n",
      "max_logprob_all:  -21.328758721894815\n",
      "chom:  chr7\n",
      "# of seqs:  15\n",
      "count:  5\n",
      "avg_logprob:  -6.4961322276247015\n",
      "max_logprob:  -21.708643588226888\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr8\n",
      "# of seqs:  21\n",
      "count:  7\n",
      "avg_logprob:  -6.674448692960534\n",
      "max_logprob:  -21.510405118121515\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr9\n",
      "# of seqs:  9\n",
      "count:  3\n",
      "avg_logprob:  -5.693710442205008\n",
      "max_logprob:  -18.66794990303381\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr10\n",
      "# of seqs:  16\n",
      "count:  1\n",
      "avg_logprob:  -1.3160267344552232\n",
      "max_logprob:  -21.05642775128357\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr11\n",
      "# of seqs:  23\n",
      "count:  7\n",
      "avg_logprob:  -5.318709870091828\n",
      "max_logprob:  -20.21029028502949\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr12\n",
      "# of seqs:  26\n",
      "count:  6\n",
      "avg_logprob:  -4.28041195294597\n",
      "max_logprob:  -20.76055305393512\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr13\n",
      "# of seqs:  10\n",
      "count:  3\n",
      "avg_logprob:  -5.509273387590374\n",
      "max_logprob:  -19.371197179846277\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr14\n",
      "# of seqs:  11\n",
      "count:  2\n",
      "avg_logprob:  -3.498523219751537\n",
      "max_logprob:  -20.20850246271013\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr15\n",
      "# of seqs:  6\n",
      "count:  0\n",
      "avg_logprob:  0.0\n",
      "max_logprob:  0\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr16\n",
      "# of seqs:  16\n",
      "count:  3\n",
      "avg_logprob:  -3.2017471277316214\n",
      "max_logprob:  -20.12385131643768\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr17\n",
      "# of seqs:  23\n",
      "count:  6\n",
      "avg_logprob:  -4.947295256881313\n",
      "max_logprob:  -19.66124506297124\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr18\n",
      "# of seqs:  3\n",
      "count:  1\n",
      "avg_logprob:  -6.63500394115781\n",
      "max_logprob:  -19.90501182347343\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr19\n",
      "# of seqs:  22\n",
      "count:  7\n",
      "avg_logprob:  -5.970783381169608\n",
      "max_logprob:  -21.149837206917105\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr20\n",
      "# of seqs:  13\n",
      "count:  2\n",
      "avg_logprob:  -2.8767152785939585\n",
      "max_logprob:  -20.231477517311365\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr21\n",
      "# of seqs:  3\n",
      "count:  1\n",
      "avg_logprob:  -6.163156241666396\n",
      "max_logprob:  -18.48946872499919\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chr22\n",
      "# of seqs:  11\n",
      "count:  1\n",
      "avg_logprob:  -1.8441571150613798\n",
      "max_logprob:  -20.28572826567518\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n",
      "chom:  chrX\n",
      "# of seqs:  10\n",
      "count:  2\n",
      "avg_logprob:  -4.100456204543022\n",
      "max_logprob:  -21.099290490833813\n",
      "=============\n",
      "max_logprob_all:  -21.708643588226888\n"
     ]
    }
   ],
   "source": [
    "# Find the log probability threshold\n",
    "\n",
    "max_logprob_all = 0\n",
    "for chom in list_chrs:\n",
    "    print(\"chom: \", chom)\n",
    "    filename = \"./ExtractedSeqs_\" + tf + \"/seqs_\" + tf + \"_fwd_pos/seqs_\" + chom + \"_\" + tf + \"_fwd_pos.fasta\"\n",
    "    sum_logprob = 0\n",
    "    avg_logprob = 0\n",
    "    max_logprob = 0\n",
    "\n",
    "    n_seqs = len([len(rec) for rec in SeqIO.parse(filename, \"fasta\")])\n",
    "    print(\"# of seqs: \", n_seqs)\n",
    "\n",
    "    with open(filename, \"r\") as fh: #rU\n",
    "        count = 0\n",
    "        for seq_record in SeqIO.parse(fh, \"fasta\"):\n",
    "            #print(seq_record.id)\n",
    "            sequence = seq_record.seq\n",
    "            #print(sequence)\n",
    "            #print(sequence[12])\n",
    "            target_seq = sequence\n",
    "            k = 0\n",
    "            log_prob = 0\n",
    "            if target_seq[k+2] != \"T\" and target_seq[k+2] != \"t\" and target_seq[k+3] != \"G\" and target_seq[k+3] != \"g\" and target_seq[k+4] != \"T\" and target_seq[k+4] != \"t\" and target_seq[k+9] != \"C\" and target_seq[k+9] != \"c\" and target_seq[k+9] != \"A\" and target_seq[k+9] != \"a\":\n",
    "                #print(\"Success\")\n",
    "                count += 1\n",
    "                for i in range(20):\n",
    "                    if target_seq[i] == 'A' or target_seq[i] == 'a':\n",
    "                        arr_idx = 0\n",
    "                    elif target_seq[i] == 'C' or target_seq[i] == 'c':\n",
    "                        arr_idx = 1\n",
    "                    elif target_seq[i] == 'G' or target_seq[i] == 'g':\n",
    "                        arr_idx = 2\n",
    "                    elif target_seq[i] == 'T' or target_seq[i] == 't':\n",
    "                        arr_idx = 3\n",
    "                    else: # if \"N\"\n",
    "                        break\n",
    "                    #print(i)\n",
    "                    #print(arr_idx)\n",
    "                    #print(\"PWM:\", pwm_arr2[arr_idx, i])\n",
    "                    log_prob += math.log(pwm_arr2[arr_idx, i])\n",
    "                    #prob = prob * (pwm_arr2[arr_idx, j])\n",
    "                    #print(\"===========\")\n",
    "                    #print(\"log_prob: \", log_prob)\n",
    "                #print(\"log_prob2: \", log_prob)\n",
    "                sum_logprob += log_prob\n",
    "                if max_logprob > log_prob:\n",
    "                    max_logprob = log_prob\n",
    "\n",
    "            #print(\"count: \", count)\n",
    "        #print(\"sum_logprob: \", sum_logprob)\n",
    "        avg_logprob = sum_logprob / n_seqs\n",
    "        print(\"count: \", count)\n",
    "        print(\"avg_logprob: \", avg_logprob)\n",
    "        print(\"max_logprob: \", max_logprob)        \n",
    "        print(\"=============\")\n",
    "    if max_logprob_all > max_logprob:\n",
    "        max_logprob_all = max_logprob\n",
    "    print(\"max_logprob_all: \", max_logprob_all)\n",
    "    logp_thresh = math.floor(max_logprob_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability threshold: -22\n"
     ]
    }
   ],
   "source": [
    "print(\"log probability threshold:\", logp_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Determination of threshold: Result\n",
    "* E.g. for TBP: Based on the above code, it was observed that the maximum log probability was almost for all in the -21s (some in the -20s). Therefore, the student decided to set the threshold as -22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identification of unbound sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of sequences contained in the fasta: 324\n"
     ]
    }
   ],
   "source": [
    "filename = \"./ExtractedSeqs_\" + tf + \"/seqs_\" + tf + \"_fwd_neg/seqs_chr1_\" + tf + \"_fwd_neg.fasta\"\n",
    "n_seqs = len([len(rec) for rec in SeqIO.parse(filename, \"fasta\")])\n",
    "print(\"# of sequences contained in the fasta:\", n_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save computational time, I will make the unbound sequence under the assumption that each region in the bedfile contains one binding site for TBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chom:  chr1\n",
      "chom:  chr2\n",
      "chom:  chr3\n",
      "chom:  chr4\n",
      "chom:  chr5\n",
      "chom:  chr6\n",
      "chom:  chr7\n",
      "chom:  chr8\n",
      "chom:  chr9\n",
      "chom:  chr10\n",
      "chom:  chr11\n",
      "chom:  chr12\n",
      "chom:  chr13\n",
      "chom:  chr14\n",
      "chom:  chr15\n",
      "chom:  chr16\n",
      "chom:  chr17\n",
      "chom:  chr18\n",
      "chom:  chr19\n",
      "chom:  chr20\n",
      "chom:  chr21\n",
      "chom:  chr22\n",
      "chom:  chrX\n",
      "Running time of grid search to identify negative examples: 50.111997842788696\n"
     ]
    }
   ],
   "source": [
    "s_time = time.time()\n",
    "fileout = \"./ExtractedSeqs_\" + tf + \"/seqs_\" + tf + \"_fwd_neg/unbound/seqs_\" + tf + \"_fwd_neg_unbound.fasta\"\n",
    "for chom in list_chrs:\n",
    "    print(\"chom: \", chom)\n",
    "    filename = \"./ExtractedSeqs_\" + tf + \"/seqs_\" + tf + \"_fwd_neg/seqs_\" + chom + \"_\" + tf + \"_fwd_neg.fasta\"\n",
    "    #logp_thresh = -22\n",
    "    \n",
    "    with open(filename, \"r\") as fh:\n",
    "        with open(fileout, \"a\") as fout:\n",
    "            for seq_record in SeqIO.parse(fh, \"fasta\"):\n",
    "                sequence = seq_record.seq\n",
    "                #print(sequence)\n",
    "                start_time = time.time()\n",
    "                #print(\"length of the seq:\", len(sequence))\n",
    "                count2 = 0\n",
    "                for j in range(len(sequence)-20):\n",
    "                    #print(\"j:\", j)\n",
    "                    count += 1\n",
    "                    target_seq = sequence[j:j+20]\n",
    "                    if \"N\" in target_seq:\n",
    "                        N_in = \"YesN\"\n",
    "                    else:\n",
    "                        N_in = \"NoN\"\n",
    "                    if N_in == \"NoN\":\n",
    "                        if target_seq[k+12] != \"G\" and target_seq[k+12] != \"g\" and target_seq[k+13] != \"G\" and target_seq[k+13] != \"g\" and target_seq[k+14] != \"G\" and target_seq[k+14] != \"g\" and target_seq[k+14] != \"C\" and target_seq[k+14] != \"c\" and target_seq[k+15] != \"G\" and target_seq[k+15] != \"g\" and target_seq[k+15] != \"C\" and target_seq[k+15] != \"c\" and target_seq[k+16] != \"G\" and target_seq[k+16] != \"g\" and target_seq[k+17] != \"G\" and target_seq[k+17] != \"g\":\n",
    "                        #if target_seq[k+2] != \"T\" and target_seq[k+2] != \"t\" and target_seq[k+3] != \"G\" and target_seq[k+3] != \"g\" and target_seq[k+4] != \"T\" and target_seq[k+4] != \"t\" and target_seq[k+9] != \"C\" and target_seq[k+9] != \"c\" and target_seq[k+9] != \"A\" and target_seq[k+9] != \"a\":\n",
    "                            log_prob = 0\n",
    "                            for i in range(20):\n",
    "                                if target_seq[i] == 'A' or target_seq[i] == 'a':\n",
    "                                    arr_idx = 0\n",
    "                                elif target_seq[i] == 'C' or target_seq[i] == 'c':\n",
    "                                    arr_idx = 1\n",
    "                                elif target_seq[i] == 'G' or target_seq[i] == 'g':\n",
    "                                    arr_idx = 2\n",
    "                                elif target_seq[i] == 'T' or target_seq[i] == 't':\n",
    "                                    arr_idx = 3\n",
    "                                else: # if \"N\"\n",
    "                                    break\n",
    "\n",
    "                                #print(pwm_arr2[arr_idx, i])\n",
    "                                log_prob += math.log(pwm_arr2[arr_idx, i])\n",
    "                            #print(\"log_prob:\", log_prob)\n",
    "                            if log_prob > logp_thresh: # if sum_logprob > -22\n",
    "                                #print(\"Written\")\n",
    "                                #print(target_seq)\n",
    "                                #print(type(str(target_seq)))\n",
    "                                fout.write(str(target_seq)+\"\\n\")\n",
    "                                #SeqIO.write(target_seq, fout, \"fasta\") \n",
    "                                #count2 += 1\n",
    "                                #print(count2)\n",
    "\n",
    "                #print(\"count:\", count)\n",
    "                end_time = time.time()\n",
    "                time_taken = end_time - start_time\n",
    "                #print(\"run time:\", time_taken)\n",
    "e_time = time.time()\n",
    "r_time = e_time - s_time\n",
    "print(\"Running time of grid search to identify negative examples:\", r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ExtractedSeqs/seqs_TBP_fwd_neg/seqs_chr1_TBP_fwd_neg.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-db27ec86fecb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./ExtractedSeqs/seqs_TBP_fwd_neg/seqs_chr1_TBP_fwd_neg.fasta\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mn_seqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fasta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# of sequences contained in the fasta:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_seqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfileout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"seqs_chr1_TBP_fwd_neg_unbound.fasta\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\Bio\\SeqIO\\__init__.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(handle, format, alphabet)\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[0miterator_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FormatToIterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0miterator_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mAlignIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FormatToIterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[1;31m# Use Bio.AlignIO to read in the alignments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\Bio\\SeqIO\\FastaIO.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, source, alphabet, title2ids)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The alphabet argument is no longer supported\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle2ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle2ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Fasta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\Bio\\SeqIO\\Interfaces.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, source, alphabet, mode, fmt)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The alphabet argument is no longer supported\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_close_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# not a path, assume we received a stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ExtractedSeqs/seqs_TBP_fwd_neg/seqs_chr1_TBP_fwd_neg.fasta'"
     ]
    }
   ],
   "source": [
    "filename = \"./ExtractedSeqs/seqs_TBP_fwd_neg/seqs_chr1_TBP_fwd_neg.fasta\"\n",
    "n_seqs = len([len(rec) for rec in SeqIO.parse(filename, \"fasta\")])\n",
    "print(\"# of sequences contained in the fasta:\", n_seqs)\n",
    "fileout = \"seqs_chr1_TBP_fwd_neg_unbound.fasta\"\n",
    "\n",
    "with open(filename, \"r\") as fh:\n",
    "    with open(fileout, \"w\") as fout:\n",
    "        records = list(SeqIO.parse(fh, \"fasta\"))\n",
    "        sample_seq = records[0].seq  # first record\n",
    "        print(sample_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time up until this point: 131.36145496368408\n"
     ]
    }
   ],
   "source": [
    "end_time_overall = time.time()\n",
    "overall_run_time = end_time_overall - start_time_overall\n",
    "print(\"Running time up until this point:\", overall_run_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. Data-Preprocessing: \n",
    "## Mini-objective: Given an input, predict whether the site is bound or unbound\n",
    "Assumption: All the input sequence is of length 20bp (length of a TBP binding site) and it should be bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MGW', 'HelT', 'Roll', 'ProT']\n"
     ]
    }
   ],
   "source": [
    "bad_words = ['>']\n",
    "list_DNAprops = [\"MGW\", \"HelT\", \"Roll\", \"ProT\"]\n",
    "print(list_DNAprops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ExtractedSeqs_TBP/phpnRRPIR_neg/phpnRRPIR.MGW.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-44b8624fe65f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfileout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./ExtractedSeqs_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtf\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdnashape_neg\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mzipname_neg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_processed.\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprop\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilein\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moldfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnewfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mlist_header\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ExtractedSeqs_TBP/phpnRRPIR_neg/phpnRRPIR.MGW.txt'"
     ]
    }
   ],
   "source": [
    "# Create textfiles that will later be converted to pandas dataframe\n",
    "for prop in list_DNAprops:\n",
    "    filein = \"./ExtractedSeqs_\" + tf + \"/\" + dnashape_neg +\"/\" + zipname_neg + \".\" + prop + \".txt\"\n",
    "    fileout = \"./ExtractedSeqs_\" + tf + \"/\" + dnashape_neg +\"/\" + zipname_neg + \"_processed.\" + prop + \".txt\"\n",
    "\n",
    "    with open(filein) as oldfile, open(fileout, 'w') as newfile:\n",
    "        n = 20\n",
    "        list_header = [prop] * n\n",
    "        #print(list_header)\n",
    "        for j in range(n):\n",
    "            list_header[j] = list_header[j] + str(j+1)\n",
    "        header = ','.join(list_header)\n",
    "        print(header)\n",
    "        newfile.write(header)\n",
    "        newfile.write(\"\\n\")\n",
    "        for line in oldfile:\n",
    "            if not any(bad_word in line for bad_word in bad_words):\n",
    "                newfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./ExtractedSeqs_UA7/phpOiEffH_neg/phpOiEffH_processed.MGW.txt', './ExtractedSeqs_UA7/phpOiEffH_neg/phpOiEffH_processed.HelT.txt', './ExtractedSeqs_UA7/phpOiEffH_neg/phpOiEffH_processed.Roll.txt', './ExtractedSeqs_UA7/phpOiEffH_neg/phpOiEffH_processed.ProT.txt']\n"
     ]
    }
   ],
   "source": [
    "files_unbound = [\"./ExtractedSeqs_\" + tf + \"/\" + dnashape_neg +\"/\" + zipname_neg + \"_processed.\" + prop + \".txt\" for prop in list_DNAprops]\n",
    "print(files_unbound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ExtractedSeqs_UA7/phpOiEffH_neg/phpOiEffH_processed.MGW.txt\n",
      "./ExtractedSeqs_UA7/phpOiEffH_neg/phpOiEffH_processed.HelT.txt\n",
      "./ExtractedSeqs_UA7/phpOiEffH_neg/phpOiEffH_processed.Roll.txt\n",
      "./ExtractedSeqs_UA7/phpOiEffH_neg/phpOiEffH_processed.ProT.txt\n",
      "(3850, 80)\n",
      "(3850, 81)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(files_unbound)):\n",
    "    if i == 0:\n",
    "        print(files_unbound[i])\n",
    "        df_properties_ub = pd.read_csv(files_unbound[i])\n",
    "    \n",
    "    else:\n",
    "        print(files_unbound[i])\n",
    "        df_property_ub = pd.read_csv(files_unbound[i])\n",
    "        df_properties_ub = pd.concat([df_properties_ub, df_property_ub.reindex(df_properties_ub.index)], axis=1)\n",
    "\n",
    "print(df_properties_ub.shape)\n",
    "df_properties_ub[\"label\"] = \"unbound\"\n",
    "print(df_properties_ub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Repeat the procedure for bound sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGW1,MGW2,MGW3,MGW4,MGW5,MGW6,MGW7,MGW8,MGW9,MGW10,MGW11,MGW12,MGW13,MGW14,MGW15,MGW16,MGW17,MGW18,MGW19,MGW20\n",
      "HelT1,HelT2,HelT3,HelT4,HelT5,HelT6,HelT7,HelT8,HelT9,HelT10,HelT11,HelT12,HelT13,HelT14,HelT15,HelT16,HelT17,HelT18,HelT19,HelT20\n",
      "Roll1,Roll2,Roll3,Roll4,Roll5,Roll6,Roll7,Roll8,Roll9,Roll10,Roll11,Roll12,Roll13,Roll14,Roll15,Roll16,Roll17,Roll18,Roll19,Roll20\n",
      "ProT1,ProT2,ProT3,ProT4,ProT5,ProT6,ProT7,ProT8,ProT9,ProT10,ProT11,ProT12,ProT13,ProT14,ProT15,ProT16,ProT17,ProT18,ProT19,ProT20\n"
     ]
    }
   ],
   "source": [
    "# Create textfiles that will later be converted to pandas dataframe\n",
    "for prop in list_DNAprops:\n",
    "    filein = \"./ExtractedSeqs_\" + tf + \"/\" + dnashape_pos +\"/\" + zipname_pos + \".\" + prop + \".txt\"\n",
    "    fileout = \"./ExtractedSeqs_\" + tf + \"/\" + dnashape_pos +\"/\" + zipname_pos + \"_processed.\" + prop + \".txt\"\n",
    "\n",
    "    with open(filein) as oldfile, open(fileout, 'w') as newfile:\n",
    "        n = 20\n",
    "        list_header = [prop] * n\n",
    "        #print(list_header)\n",
    "        for j in range(n):\n",
    "            list_header[j] = list_header[j] + str(j+1)\n",
    "        header = ','.join(list_header)\n",
    "        print(header)\n",
    "        newfile.write(header)\n",
    "        newfile.write(\"\\n\")\n",
    "        for line in oldfile:\n",
    "            if not any(bad_word in line for bad_word in bad_words):\n",
    "                newfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./ExtractedSeqs_UA7/phpKXASSB_pos/phpKXASSB_processed.MGW.txt', './ExtractedSeqs_UA7/phpKXASSB_pos/phpKXASSB_processed.HelT.txt', './ExtractedSeqs_UA7/phpKXASSB_pos/phpKXASSB_processed.Roll.txt', './ExtractedSeqs_UA7/phpKXASSB_pos/phpKXASSB_processed.ProT.txt']\n"
     ]
    }
   ],
   "source": [
    "files_bound = [\"./ExtractedSeqs_\" + tf + \"/\" + dnashape_pos +\"/\" + zipname_pos + \"_processed.\" + prop + \".txt\" for prop in list_DNAprops]\n",
    "print(files_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ExtractedSeqs_UA7/phpKXASSB_pos/phpKXASSB_processed.MGW.txt\n",
      "./ExtractedSeqs_UA7/phpKXASSB_pos/phpKXASSB_processed.HelT.txt\n",
      "./ExtractedSeqs_UA7/phpKXASSB_pos/phpKXASSB_processed.Roll.txt\n",
      "./ExtractedSeqs_UA7/phpKXASSB_pos/phpKXASSB_processed.ProT.txt\n",
      "(2476, 80)\n",
      "(2476, 81)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(files_bound)):\n",
    "    if i == 0:\n",
    "        print(files_bound[i])\n",
    "        df_properties_b = pd.read_csv(files_bound[i])    \n",
    "    else:\n",
    "        print(files_bound[i])\n",
    "        df_property_b = pd.read_csv(files_bound[i])\n",
    "        df_properties_b = pd.concat([df_properties_b, df_property_b.reindex(df_properties_b.index)], axis=1)\n",
    "\n",
    "print(df_properties_b.shape)\n",
    "df_properties_b[\"label\"] = \"bound\"\n",
    "print(df_properties_b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge the dataframes of bound and unbound sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6326, 81)\n"
     ]
    }
   ],
   "source": [
    "df_properties_both = pd.concat([df_properties_ub, df_properties_b], axis=0)\n",
    "print(df_properties_both.shape)\n",
    "#print(df_properties_both.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop columns whose values are all NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties_both = df_properties_both.dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6326\n",
      "71\n",
      "      MGW3  MGW4  MGW5  MGW6  MGW7  MGW8  MGW9  MGW10  MGW11  MGW12  ...  \\\n",
      "1220  4.63  4.36  4.03  4.63  5.18  5.54  5.51   5.08   4.69   4.73  ...   \n",
      "3376  5.56  5.42  4.95  4.06  4.03  4.70  5.30   5.51   5.54   5.18  ...   \n",
      "194   4.76  3.38  3.63  4.12  4.46  5.34  5.47   4.94   4.82   5.33  ...   \n",
      "2037  5.31  4.92  4.65  4.73  4.45  4.29  4.85   5.47   5.56   4.89  ...   \n",
      "1188  4.76  4.63  4.36  4.03  4.14  4.80  5.53   5.31   5.02   4.93  ...   \n",
      "354   5.42  4.76  4.05  4.65  4.30  4.99  5.34   4.97   4.84   4.94  ...   \n",
      "2333  4.74  4.36  4.03  4.17  4.61  4.95  5.19   5.36   4.96   4.72  ...   \n",
      "2537  3.38  3.38  3.68  4.03  4.14  4.80  5.67   5.79   5.79   5.75  ...   \n",
      "646   4.63  4.27  2.85  3.75  4.43  5.14  5.56   5.39   4.89   4.82  ...   \n",
      "944   5.50  5.20  5.58  4.98  4.64  5.20  5.51   5.27   5.01   5.05  ...   \n",
      "728   4.63  4.35  4.05  4.06  4.03  4.70  4.92   4.62   4.74   4.84  ...   \n",
      "3176  5.56  5.42  4.52  4.03  4.14  4.80  5.67   5.41   5.17   5.37  ...   \n",
      "157   5.42  4.76  3.38  3.68  4.03  4.63  5.15   5.27   5.01   4.93  ...   \n",
      "1016  5.40  4.35  3.63  4.12  3.75  4.98  5.56   5.19   4.84   5.31  ...   \n",
      "237   4.74  4.35  4.05  3.85  3.95  4.93  5.13   5.29   5.71   6.01  ...   \n",
      "1659  5.56  5.31  4.65  4.51  4.33  4.95  5.53   5.43   4.93   4.72  ...   \n",
      "227   4.73  4.84  4.46  4.03  4.58  4.94  5.19   5.36   5.17   5.41  ...   \n",
      "566   4.98  4.36  4.02  4.68  5.04  5.02  5.15   5.27   5.01   5.05  ...   \n",
      "1909  4.76  4.63  4.31  3.74  4.89  5.67  5.47   4.92   4.81   4.80  ...   \n",
      "2462  3.38  3.38  4.05  4.06  3.64  4.54  5.47   5.93   5.40   4.74  ...   \n",
      "441   5.01  4.92  4.93  5.04  4.63  4.80  5.53   5.43   5.24   5.66  ...   \n",
      "1826  5.45  4.94  4.17  4.61  4.73  4.85  5.40   5.39   4.96   4.61  ...   \n",
      "1396  5.41  4.52  4.03  4.17  4.53  5.43  5.40   4.94   4.82   5.41  ...   \n",
      "2852  5.80  5.32  5.31  4.95  4.61  4.95  5.19   5.39   5.01   5.05  ...   \n",
      "1131  5.91  4.70  4.05  4.42  4.68  4.85  4.93   4.85   4.72   4.93  ...   \n",
      "1681  5.30  5.45  4.94  4.17  4.61  4.95  5.19   5.36   5.09   5.41  ...   \n",
      "2173  5.70  5.24  4.95  5.31  5.27  5.16  5.40   5.13   5.54   6.20  ...   \n",
      "455   5.62  4.81  4.42  4.73  4.61  4.95  5.53   5.39   4.89   4.76  ...   \n",
      "32    5.86  5.17  5.05  5.31  4.77  4.70  5.19   5.36   5.09   5.29  ...   \n",
      "52    4.63  4.36  4.03  4.17  4.33  4.94  5.40   5.43   4.93   4.77  ...   \n",
      "...    ...   ...   ...   ...   ...   ...   ...    ...    ...    ...  ...   \n",
      "1103  5.41  4.95  4.06  4.03  4.29  4.85  5.52   5.41   5.02   4.73  ...   \n",
      "1402  5.41  4.12  4.12  4.46  4.79  5.27  5.34   4.97   5.13   5.43  ...   \n",
      "2880  5.14  5.00  4.93  5.04  4.67  4.83  5.36   5.39   5.01   4.93  ...   \n",
      "282   5.08  5.42  4.52  4.03  4.14  4.80  5.53   5.39   4.93   4.73  ...   \n",
      "2952  5.40  4.65  4.51  4.72  4.72  4.94  5.40   5.43   4.93   4.77  ...   \n",
      "473   5.09  4.63  4.82  4.17  4.33  4.94  5.40   5.31   5.02   4.73  ...   \n",
      "18    5.41  4.52  4.05  4.42  4.73  4.96  5.29   5.37   4.96   4.77  ...   \n",
      "1225  4.63  4.96  5.28  5.40  4.77  4.94  5.40   5.31   5.02   4.92  ...   \n",
      "1927  5.21  4.52  4.02  4.65  4.99  5.26  5.29   4.85   4.73   5.02  ...   \n",
      "1399  5.94  5.15  4.82  4.63  5.18  5.54  5.51   5.37   5.09   5.41  ...   \n",
      "1562  3.38  3.38  3.68  4.05  4.31  4.63  4.93   4.37   4.42   5.40  ...   \n",
      "766   5.42  4.76  4.05  4.06  3.64  4.54  5.40   5.31   4.97   4.63  ...   \n",
      "936   4.73  4.63  4.74  4.06  4.03  4.70  5.19   5.19   4.95   4.61  ...   \n",
      "3841  5.31  4.65  4.51  4.72  4.77  4.95  5.30   5.29   4.96   4.82  ...   \n",
      "1976  4.73  4.84  4.46  4.03  4.58  4.94  5.19   5.39   5.09   4.63  ...   \n",
      "1170  4.92  4.31  3.74  4.51  4.81  4.92  5.40   5.19   4.84   4.80  ...   \n",
      "1734  5.43  5.40  4.94  4.72  4.93  5.43  5.40   4.94   4.72   4.93  ...   \n",
      "2122  4.63  4.63  3.75  4.18  4.94  5.67  5.47   4.94   4.72   4.72  ...   \n",
      "998   5.15  4.63  4.51  4.72  4.72  4.94  5.40   5.31   5.02   4.92  ...   \n",
      "1094  4.90  5.02  5.49  5.31  4.77  4.70  5.19   5.39   5.01   5.05  ...   \n",
      "2314  5.42  4.95  4.06  4.36  5.16  5.19  4.94   4.76   4.85   5.05  ...   \n",
      "550   4.76  4.63  4.82  4.17  4.53  5.43  5.40   4.85   4.73   5.02  ...   \n",
      "3178  4.74  4.36  4.03  4.17  4.53  5.43  5.40   4.85   4.29   4.77  ...   \n",
      "1253  5.31  4.92  4.65  4.57  3.74  4.52  5.31   5.44   4.96   4.61  ...   \n",
      "1750  4.85  4.93  4.85  4.72  4.77  4.95  5.19   5.19   4.94   4.82  ...   \n",
      "3469  4.63  4.63  4.42  4.62  4.58  4.77  5.56   5.58   5.19   5.02  ...   \n",
      "1202  5.30  5.41  4.52  4.03  4.61  5.16  5.52   4.85   4.62   4.82  ...   \n",
      "144   5.41  4.12  4.12  4.19  4.51  4.92  5.40   5.39   4.89   4.82  ...   \n",
      "1098  4.63  4.36  4.02  4.65  4.57  5.00  5.32   5.43   4.53   4.95  ...   \n",
      "3425  4.63  4.36  4.03  4.17  4.33  4.94  5.40   5.39   4.89   4.82  ...   \n",
      "\n",
      "      ProT10  ProT11  ProT12  ProT13  ProT14  ProT15  ProT16  ProT17  ProT18  \\\n",
      "1220   -4.55   -5.99   -8.04   -3.97   -6.69   -3.60   -1.60   -6.12  -10.65   \n",
      "3376   -4.25   -4.22   -3.87   -1.72   -5.87   -2.47   -2.02   -1.44   -4.39   \n",
      "194    -1.28   -2.38   -3.12   -9.43   -9.01   -4.33   -7.00   -7.11   -4.03   \n",
      "2037   -5.31   -6.08   -7.50   -3.31   -7.68   -3.74   -3.74   -8.40   -8.46   \n",
      "1188   -2.98   -5.45   -5.75   -0.70   -2.82   -3.39   -4.22   -4.25   -2.75   \n",
      "354    -4.33   -6.17   -7.96   -6.37   -9.26  -10.15   -8.83   -7.82   -6.82   \n",
      "2333   -3.58   -2.72   -2.20   -0.70   -6.32   -6.12   -3.04   -6.07   -7.55   \n",
      "2537   -3.68   -3.68   -6.69   -3.52  -10.30   -8.18   -3.22   -6.62   -2.40   \n",
      "646    -2.47   -2.02   -2.13   -2.89   -3.63   -7.98   -7.87   -3.48   -5.78   \n",
      "944    -3.15   -5.07   -6.07   -1.32   -3.78   -2.75   -1.95   -2.13   -2.48   \n",
      "728   -10.04  -11.06   -9.91   -5.36   -3.19   -3.19   -5.07   -6.07   -0.53   \n",
      "3176   -3.20   -3.11   -3.73   -3.78   -1.72   -6.36   -6.08   -6.75   -0.53   \n",
      "157    -3.15   -5.07   -5.75   -0.44   -4.81   -5.75   -0.44   -5.39   -7.55   \n",
      "1016   -4.44   -7.00   -8.57   -8.16   -7.33   -5.00   -6.17   -7.55   -5.39   \n",
      "237    -7.95   -8.08   -6.82   -8.47   -7.38   -4.25   -3.85   -6.69   -3.97   \n",
      "1659   -3.34   -2.54   -2.20   -1.28   -5.54   -2.47   -2.02   -2.13   -2.48   \n",
      "227    -3.58   -3.11   -3.20   -5.92   -0.14   -1.88   -2.52   -3.41   -7.89   \n",
      "566    -3.15   -5.07   -6.07   -0.83   -0.83   -6.78   -6.12   -2.92   -2.56   \n",
      "1909   -0.90   -5.39   -7.55   -5.99   -4.79   -6.70   -8.43   -6.96   -1.30   \n",
      "2462   -5.95  -10.81  -12.76  -13.15  -10.39   -8.78   -7.87   -5.00   -6.17   \n",
      "441    -3.34   -2.98   -3.41   -8.40   -7.98   -4.73   -4.73   -7.98   -9.43   \n",
      "1826   -2.47   -2.77   -2.48   -1.20   -6.36   -5.95  -10.81  -12.09  -11.76   \n",
      "1396   -1.28   -2.38   -3.20   -5.92   -0.14   -1.76   -4.60   -6.75   -3.11   \n",
      "2852   -3.19   -5.07   -6.07   -0.53   -2.48   -2.73   -2.75   -4.25   -4.22   \n",
      "1131   -0.70   -2.20   -2.54   -4.03   -7.87   -8.46   -2.81   -2.56   -4.91   \n",
      "1681   -3.58   -3.17   -3.39   -3.39   -2.89   -2.73   -2.75   -3.13   -2.89   \n",
      "2173   -4.20   -8.16   -8.00   -7.17  -10.72   -9.12   -3.22   -6.38   -0.70   \n",
      "455    -2.47   -2.02   -1.44   -4.60   -5.75   -0.88   -5.67   -8.04   -3.46   \n",
      "32     -3.58   -3.17   -3.13   -3.73   -3.17   -3.39   -4.22   -4.25   -3.73   \n",
      "52     -3.34   -2.54   -1.93   -2.77   -2.47   -6.09   -3.06   -6.50   -0.94   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "1103   -3.20   -2.52   -1.88   -0.03   -6.32   -6.12   -3.04   -5.07   -5.75   \n",
      "1402   -4.33   -5.96   -7.21  -10.31   -8.13   -1.50   -2.34   -1.20   -6.76   \n",
      "2880   -3.19   -5.07   -5.75   -0.03   -1.32   -1.03   -2.37   -5.89   -7.89   \n",
      "282    -2.47   -2.42   -4.39   -9.44   -7.38   -1.50   -2.34   -0.53   -6.07   \n",
      "2952   -3.34   -2.54   -1.93   -2.77   -2.47   -6.09   -2.70   -7.85   -7.37   \n",
      "473    -2.98   -5.45   -6.75   -3.31   -7.40   -2.94   -2.77   -2.89   -3.13   \n",
      "18     -3.73   -2.72   -1.93   -2.77   -2.47   -7.24   -4.52   -7.68   -4.13   \n",
      "1225   -2.98   -5.45   -6.10   -2.54   -6.38   -0.44   -4.81   -6.07   -0.53   \n",
      "1927   -0.14   -1.88   -2.52   -3.20   -5.92   -1.28   -2.82   -3.13   -4.55   \n",
      "1399   -3.73   -3.17   -3.39   -3.87   -1.72   -5.87   -2.47   -2.02   -2.13   \n",
      "1562   -0.88   -6.64   -7.04   -6.50   -6.36   -0.44   -4.81   -6.10   -2.78   \n",
      "766    -2.98   -5.20   -9.44   -8.01   -1.91   -3.56   -6.90   -8.09   -6.17   \n",
      "936    -3.26   -2.73   -2.48   -1.20   -6.36   -6.08   -6.62   -3.46   -8.49   \n",
      "3841   -3.13   -2.89   -2.13   -1.03   -1.95   -2.75   -4.25   -4.22   -4.22   \n",
      "1976   -3.19   -5.36  -10.09  -11.93  -10.71   -3.22   -7.83   -3.05   -8.16   \n",
      "1170   -4.44   -6.17   -7.55   -5.78   -3.37   -9.01   -9.01   -3.37   -5.78   \n",
      "1734   -1.28   -2.20   -2.54   -3.34   -5.87   -1.72   -3.78   -3.73   -2.72   \n",
      "2122   -1.28   -2.20   -2.20   -1.50   -9.16   -9.71   -4.69   -7.00   -7.89   \n",
      "998    -2.98   -5.45   -6.10   -2.40  -10.30   -8.18   -3.46  -10.59  -10.08   \n",
      "1094   -3.19   -5.07   -6.07   -0.94   -3.68   -9.43   -9.43   -4.03   -3.94   \n",
      "2314   -1.44   -4.60   -6.07   -1.32   -3.78   -2.75   -2.56   -5.28   -7.55   \n",
      "550    -0.14   -1.88   -2.52   -3.20   -5.92   -0.14   -1.32   -1.03   -2.37   \n",
      "3178   -0.14   -2.62   -5.89   -7.11   -2.94   -2.42   -4.39   -9.91  -11.06   \n",
      "1253   -3.45   -2.77   -2.48   -1.55   -8.63   -9.71   -3.45   -3.38   -5.33   \n",
      "1750   -3.26   -1.95   -2.13   -2.48   -1.20   -5.87   -2.98   -5.78   -8.11   \n",
      "3469   -3.48   -5.78   -7.71   -6.88   -7.34   -1.72   -3.60   -7.79   -5.42   \n",
      "1202   -0.14   -1.32   -2.13   -2.89   -3.13   -3.73   -3.17   -3.13   -3.73   \n",
      "144    -2.47   -2.02   -2.13   -2.89   -3.13   -3.15   -6.07   -7.55   -6.17   \n",
      "1098   -3.34   -2.76   -1.20   -5.87   -2.47   -2.42   -4.39   -9.44   -8.01   \n",
      "3425   -2.47   -2.02   -2.13   -1.93   -1.93   -2.13   -2.02   -2.47   -6.09   \n",
      "\n",
      "        label  \n",
      "1220    bound  \n",
      "3376  unbound  \n",
      "194     bound  \n",
      "2037  unbound  \n",
      "1188  unbound  \n",
      "354     bound  \n",
      "2333  unbound  \n",
      "2537  unbound  \n",
      "646     bound  \n",
      "944   unbound  \n",
      "728     bound  \n",
      "3176  unbound  \n",
      "157   unbound  \n",
      "1016  unbound  \n",
      "237   unbound  \n",
      "1659  unbound  \n",
      "227   unbound  \n",
      "566   unbound  \n",
      "1909  unbound  \n",
      "2462  unbound  \n",
      "441   unbound  \n",
      "1826  unbound  \n",
      "1396  unbound  \n",
      "2852  unbound  \n",
      "1131  unbound  \n",
      "1681  unbound  \n",
      "2173  unbound  \n",
      "455   unbound  \n",
      "32      bound  \n",
      "52      bound  \n",
      "...       ...  \n",
      "1103  unbound  \n",
      "1402  unbound  \n",
      "2880  unbound  \n",
      "282   unbound  \n",
      "2952  unbound  \n",
      "473   unbound  \n",
      "18    unbound  \n",
      "1225  unbound  \n",
      "1927  unbound  \n",
      "1399  unbound  \n",
      "1562  unbound  \n",
      "766   unbound  \n",
      "936     bound  \n",
      "3841  unbound  \n",
      "1976  unbound  \n",
      "1170  unbound  \n",
      "1734  unbound  \n",
      "2122  unbound  \n",
      "998   unbound  \n",
      "1094  unbound  \n",
      "2314  unbound  \n",
      "550   unbound  \n",
      "3178  unbound  \n",
      "1253  unbound  \n",
      "1750  unbound  \n",
      "3469  unbound  \n",
      "1202    bound  \n",
      "144     bound  \n",
      "1098    bound  \n",
      "3425  unbound  \n",
      "\n",
      "[4469 rows x 67 columns]\n",
      "(4469, 67)\n"
     ]
    }
   ],
   "source": [
    "df_shuffled = sklearn.utils.shuffle(df_properties_both)\n",
    "n_rows = df_shuffled.shape[0]\n",
    "n_cols = df_shuffled.shape[1]\n",
    "print(n_rows)\n",
    "print(n_cols)\n",
    "#print(df_shuffled.shape)\n",
    "df_nan = df_shuffled.dropna(axis=0, how = 'all')\n",
    "df_nan = df_nan.dropna(thresh=n_rows*0.8, axis=1)\n",
    "df_nan = df_nan.dropna(thresh=n_cols*0.8, axis=0)\n",
    "df_nan = df_nan.dropna()\n",
    "print(df_nan)\n",
    "print(df_nan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nearest neighbour: 150\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 151\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 152\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 153\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 154\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 155\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 156\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 157\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 158\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 159\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 160\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 161\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 162\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 163\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 164\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 165\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 166\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 167\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 168\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 169\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 170\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 171\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 172\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 173\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 174\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 175\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 176\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 177\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 178\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 179\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 180\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 181\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 182\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 183\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 184\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 185\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 186\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 187\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 188\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 189\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 190\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 191\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 192\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 193\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 194\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 195\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 196\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 197\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 198\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 199\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 200\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 201\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 202\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 203\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 204\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 205\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 206\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 207\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 208\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 209\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 210\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 211\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 212\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 213\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 214\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 215\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 216\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 217\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 218\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 219\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 220\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 221\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 222\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 223\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 224\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 225\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 226\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 227\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 228\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 229\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 230\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 231\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 232\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 233\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 234\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 235\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 236\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 237\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 238\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 239\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 240\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 241\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 242\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 243\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 244\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 245\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 246\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 247\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 248\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Number of nearest neighbour: 249\n",
      "Average accuracy: 0.8614944472419088\n",
      "best n: 150\n",
      "Running time (s): 295.1816318035126\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "X = df_nan.iloc[:,:-1]\n",
    "y = df_nan.iloc[:,-1]\n",
    "\n",
    "test_accuracy = []\n",
    "\n",
    "best_accuracy = 0\n",
    "best_n = 0\n",
    "\n",
    "for i in range(1, 150):\n",
    "    n = i  # number of neighbours i.e. hyperparameter of KNN\n",
    "    k = 5\n",
    "    kf = KFold(n_splits=k)\n",
    "    knn1 = KNeighborsClassifier(n_neighbors=n)  # change n_neighbors as necessary\n",
    "\n",
    "    acc_score = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #print(train_index, test_index)\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Feature scaling\n",
    "        s = StandardScaler()\n",
    "        s.fit(X_train)\n",
    "        X_train = s.transform(X_train)\n",
    "        X_test = s.transform(X_test)\n",
    "\n",
    "        # Fit the model\n",
    "        knn1.fit(X_train, y_train)\n",
    "        pred_values = knn1.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(pred_values, y_test)\n",
    "        acc_score.append(accuracy)\n",
    "\n",
    "    avg_acc_score = sum(acc_score) / k\n",
    "    test_accuracy.append(avg_acc_score)\n",
    "    \n",
    "    if avg_acc_score > best_accuracy:\n",
    "        best_accuracy = avg_acc_score\n",
    "        best_n = n\n",
    "        \n",
    "    #print(\"Accuracy: each fold:\", acc_score)\n",
    "    print(\"Number of nearest neighbour:\", n)\n",
    "    print(\"Average accuracy:\", avg_acc_score)\n",
    "    print(\"best n:\", best_n)\n",
    "t_end = time.time()\n",
    "t_total = t_end - t_start\n",
    "print(\"Running time (s):\", t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbours with the highest accuracy: 2\n",
      "Highest accuracy achieved: 0.9252628572716957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_list = [i for i in range(1, 150)]\n",
    "print(\"Number of neighbours with the highest accuracy:\", best_n)\n",
    "print(\"Highest accuracy achieved:\", best_accuracy)\n",
    "plt.plot(n_list, test_accuracy)\n",
    "plt.title(\"UA7: Number of nearest neighors vs accuracy\")\n",
    "plt.xlabel(\"Number of nearest neighors\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nearest neighbour: 2\n",
      "Average accuracy: 0.9252628572716957\n",
      "best n: 2\n",
      "Running time (s): 2.1782264709472656\n"
     ]
    }
   ],
   "source": [
    "# Creating one KNN classifier\n",
    "t_start = time.time()\n",
    "\n",
    "X = df_nan.iloc[:,:-1]\n",
    "y = df_nan.iloc[:,-1]\n",
    "\n",
    "\n",
    "n_list = [i for i in range(1, 100)]\n",
    "test_accuracy = []\n",
    "\n",
    "best_accuracy = 0\n",
    "best_n = 0\n",
    "\n",
    "n = 2  # number of neighbours i.e. hyperparameter of KNN\n",
    "k = 5\n",
    "kf = KFold(n_splits=k)\n",
    "knn1 = KNeighborsClassifier(n_neighbors=n)  # change n_neighbors as necessary\n",
    "\n",
    "acc_score = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(train_index, test_index)\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Feature scaling\n",
    "    s = StandardScaler()\n",
    "    s.fit(X_train)\n",
    "    X_train = s.transform(X_train)\n",
    "    X_test = s.transform(X_test)\n",
    "\n",
    "    # Fit the model\n",
    "    knn1.fit(X_train, y_train)\n",
    "    pred_values = knn1.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(pred_values, y_test)\n",
    "    acc_score.append(accuracy)\n",
    "\n",
    "avg_acc_score = sum(acc_score) / k\n",
    "test_accuracy.append(avg_acc_score)\n",
    "\n",
    "if avg_acc_score > best_accuracy:\n",
    "    best_accuracy = avg_acc_score\n",
    "    best_n = n\n",
    "\n",
    "#print(\"Accuracy: each fold:\", acc_score)\n",
    "print(\"Number of nearest neighbour:\", n)\n",
    "print(\"Average accuracy:\", avg_acc_score)\n",
    "print(\"best n:\", best_n)\n",
    "t_end = time.time()\n",
    "t_total = t_end - t_start\n",
    "print(\"Running time (s):\", t_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "Average accuracy: 0.8713388497661404\n",
      "Running time (s): 1.148926019668579\n"
     ]
    }
   ],
   "source": [
    "t_start2 = time.time()\n",
    "\n",
    "X = df_nan.iloc[:,:-1]\n",
    "y = df_nan.iloc[:,-1]\n",
    "\n",
    "\n",
    "n_list = [i for i in range(1, 100)]\n",
    "print(n)\n",
    "test_accuracy = []\n",
    "\n",
    "n = i  # number of neighbours i.e. hyperparameter of KNN\n",
    "k = 5\n",
    "kf = KFold(n_splits=k)\n",
    "classifier = LogisticRegression(random_state=0, solver='liblinear')\n",
    "\n",
    "acc_score = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred_values = classifier.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(pred_values, y_test)\n",
    "    acc_score.append(accuracy)\n",
    "\n",
    "avg_acc_score = sum(acc_score) / k\n",
    "test_accuracy.append(avg_acc_score)\n",
    "\n",
    "#print(\"Accuracy: each fold:\", acc_score)\n",
    "print(\"Average accuracy:\", avg_acc_score)\n",
    "t_end2 = time.time()\n",
    "t_total2 = t_end2 - t_start2\n",
    "print(\"Running time (s):\", t_total2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform a grid search to find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "param_grid = [\n",
    "    {'classifier': [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],  # L1 and L2 regularizations\n",
    "     'classifier__C': np.logspace(-4, 4, 20),\n",
    "     'classifier__solver': ['liblinear']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create a grid search object\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_classifier = clf.fit(X_train, y_train)\n",
    "print(best_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
